{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fb46d5f-0331-4466-b441-9196a9434ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ğŸš€ 2023-11-26 Python-3.8.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3090, 24268MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n",
      "color [238 237 189]\n",
      "         xmin        ymin        xmax        ymax  confidence  class    name\n",
      "0  219.181656  407.962585  346.653259  873.797974    0.864835      0  person\n",
      "1   50.101345  395.412628  239.307892  913.109924    0.860520      0  person\n",
      "2  673.481384  400.613281  810.000000  875.121704    0.849506      0  person\n",
      "3   14.571888  219.987701  810.000000  809.948425    0.816634      5     bus\n",
      "4    0.082597  553.358582   64.700478  874.117920    0.644922      0  person\n",
      "x1:219 x2:346 y1:407 y2:873 conf:0.8648354411125183 Label: 0\n",
      "x1:50 x2:239 y1:395 y2:913 conf:0.8605201244354248 Label: 0\n",
      "x1:673 x2:810 y1:400 y2:875 conf:0.8495055437088013 Label: 0\n",
      "x1:14 x2:810 y1:219 y2:809 conf:0.8166336417198181 Label: 5\n",
      "x1:0 x2:64 y1:553 y2:874 conf:0.6449224948883057 Label: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# from YOLO.ultralytics_yolov5_master.models.experimental import attempt_load\n",
    "\n",
    "\n",
    "# from models.experimental import attempt_load\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# è®¾ç½®ç¼“å­˜ç›®å½•\n",
    "cache_dir = 'YOLO'\n",
    "torch.hub.set_dir(cache_dir)\n",
    "\n",
    "colors = np.random.randint(125, 255, (80, 3))\n",
    "\n",
    "# å®šä¹‰æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„\n",
    "model_weights_path = 'YOLO/ultralytics_yolov5_master/yolov5s.pt'\n",
    "\n",
    "\n",
    "# åŠ è½½æ¨¡å‹\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = attempt_load(model_weights_path)\n",
    "\n",
    "\n",
    "# Model\n",
    "# ../: æºç›®å½•, æŸ¥æ‰¾ hubconf.py, æ¨¡å‹æ–‡ä»¶ç­‰ï¼Œ'yolov5s'ï¼šæ‰¾æ¨¡å‹æ–‡ä»¶ï¼Œæ²¡æœ‰ä¼šä¸‹è½½  ; source='local' æœ¬åœ°åŠ è½½æ¨¡å‹\n",
    "model = torch.hub.load('YOLO/ultralytics_yolov5_master', 'yolov5s', source='local')  # or yolov5m, yolov5l, yolov5x, custom\n",
    "\n",
    "\n",
    "model.eval()  # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "print(\"model loaded\")\n",
    "\n",
    "\n",
    "\n",
    "# åŠ è½½å›¾åƒï¼ˆæˆ–è§†é¢‘å¸§ï¼‰è¿›è¡Œç›®æ ‡æ£€æµ‹\n",
    "image_path = 'bus.jpg'\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# è¿›è¡Œç›®æ ‡æ£€æµ‹\n",
    "results = model(img)\n",
    "\n",
    "# æ˜¾ç¤ºæ£€æµ‹ç»“æœ\n",
    "# results.show()\n",
    "color = colors[int(random.randint(1, 10))]\n",
    "print(\"color\", color)\n",
    "\n",
    "# æˆ–è€…è·å–æ£€æµ‹åˆ°çš„å¯¹è±¡ä¿¡æ¯å¹¶è¿›è¡Œåç»­å¤„ç†\n",
    "detected_objects = results.pandas().xyxy[0]\n",
    "print(detected_objects)\n",
    "\n",
    "for index, obj in detected_objects.iterrows():\n",
    "    x1, y1, x2, y2, conf, label = int(obj[0]), int(obj[1]), int(obj[2]), int(obj[3]), obj[4], int(obj[5])\n",
    "    print(f\"x1:{x1} x2:{x2} y1:{y1} y2:{y2} conf:{conf} Label: {label}\")\n",
    "#     ç”»å‡ºè¾¹ç•Œæ¡†\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (int(color[0]), int(color[1]), int(color[2])), 2)\n",
    "\n",
    "#     # æ ‡ç­¾æ–‡æœ¬\n",
    "    label_text = f\"{model.names[label]}: {conf:.2f}\"\n",
    "\n",
    "#     # åœ¨è¾¹ç•Œæ¡†ä¸Šæ–¹æ˜¾ç¤ºç±»åˆ«æ ‡ç­¾å’Œç½®ä¿¡åº¦\n",
    "    cv2.putText(img, label_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (int(color[0]), int(color[1]), int(color[2])), 2)\n",
    "    \n",
    "cv2.imwrite('output.jpg', img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bffb93b-41f5-4e4e-8052-b320d871462c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ğŸš€ 2023-11-26 Python-3.8.12 torch-1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3090, 24268MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n",
      "Task_id:123 0/13 img_name: table1_page_2.png\n",
      "Task: 123 The file table1_page_2.png predicted done.\n",
      "Task_id:123 1/13 img_name: test_page_0.png\n",
      "Task: 123 The file test_page_0.png predicted current object class is: tie: 0.60 axis: 394 232 432 262\n",
      "Task: 123 The file test_page_0.png predicted current object class is: person: 0.58 axis: 343 31 520 278\n",
      "Task: 123 The file test_page_0.png predicted done.\n",
      "Task_id:123 2/13 img_name: table1_page_1.png\n",
      "Task: 123 The file table1_page_1.png predicted done.\n",
      "Task_id:123 3/13 img_name: table2_page_0.png\n",
      "Task: 123 The file table2_page_0.png predicted done.\n",
      "Task_id:123 4/13 img_name: ä¸åŠ¨äº§ç™»è®°ç”³è¯·è¡¨_page_1.png\n",
      "Task: 123 The file ä¸åŠ¨äº§ç™»è®°ç”³è¯·è¡¨_page_1.png predicted done.\n",
      "Task_id:123 5/13 img_name: table2_page_1.png\n",
      "Task: 123 The file table2_page_1.png predicted done.\n",
      "Task_id:123 6/13 img_name: 02-èº«ä»½è¯_page_0.png\n",
      "Task: 123 The file 02-èº«ä»½è¯_page_0.png predicted current object class is: clock: 0.89 axis: 478 179 542 242\n",
      "Task: 123 The file 02-èº«ä»½è¯_page_0.png predicted done.\n",
      "Task_id:123 7/13 img_name: æˆ·å£æœ¬_page_0.png\n",
      "Task: 123 The file æˆ·å£æœ¬_page_0.png predicted done.\n",
      "Task_id:123 8/13 img_name: ä¸åŠ¨äº§ç™»è®°ç”³è¯·è¡¨_page_0.png\n",
      "Task: 123 The file ä¸åŠ¨äº§ç™»è®°ç”³è¯·è¡¨_page_0.png predicted done.\n",
      "Task_id:123 9/13 img_name: .ipynb_checkpoints\n",
      "Task_id:123 10/13 img_name: 03 å®—åœ°å›¾_page_0.png\n",
      "Task: 123 The file 03 å®—åœ°å›¾_page_0.png predicted done.\n",
      "Task_id:123 11/13 img_name: ä¸åŠ¨äº§ç™»è®°ç”³è¯·è¡¨_page_2.png\n",
      "Task: 123 The file ä¸åŠ¨äº§ç™»è®°ç”³è¯·è¡¨_page_2.png predicted done.\n",
      "Task_id:123 12/13 img_name: table1_page_0.png\n",
      "Task: 123 The file table1_page_0.png predicted done.\n",
      "{'æˆ·å£æœ¬.pdf': {'file_type': 'PDF'}, '02å…¬ç¤ºæ— å¼‚è®®è¯æ˜.docx': {'file_type': 'DOCX'}, '03 å®—åœ°å›¾.pdf': {'file_type': 'PDF'}, '02-èº«ä»½è¯.pdf': {'file_type': 'PDF', 'result': [{'class_id': 74, 'label': 'clock: 0.89', 'bbox': [478, 179, 542, 242], 'score': 0.8892048597335815}]}, 'ä¸åŠ¨äº§ç™»è®°ç”³è¯·è¡¨.pdf': {'file_type': 'PDF'}, 'table2.pdf': {'file_type': 'PDF'}, 'pre_process': {'file_type': 'PRE_PROCESS'}, 'test.jpeg': {'file_type': 'JPEG', 'result': [{'class_id': 27, 'label': 'tie: 0.60', 'bbox': [394, 232, 432, 262], 'score': 0.5978972911834717}, {'class_id': 0, 'label': 'person: 0.58', 'bbox': [343, 31, 520, 278], 'score': 0.5780764222145081}]}, 'table1.pdf': {'file_type': 'PDF'}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import sys\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import pdfplumber\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# from YOLO.ultralytics_yolov5_master.models.experimental import attempt_load\n",
    "# from models.experimental import attempt_load\n",
    "\n",
    "\n",
    "\n",
    "def pre_process(images_path, pre_process_path):\n",
    "    res_dict = dict()\n",
    "    file_list = os.listdir(images_path)\n",
    "\n",
    "    \n",
    "    for idx, filename in enumerate(file_list):\n",
    "        file_extension = filename.split(\".\")[-1]\n",
    "        file_name = filename.split(\".\")[0]\n",
    "        res_dict[filename] = {\"file_type\": file_extension.upper()}\n",
    "\n",
    "        detection_type_list = [\"pdf\", \"png\", \"jpg\", \"jpeg\"]\n",
    "        img_extension_list = [\"png\", \"jpg\", \"jpeg\"]\n",
    "        if file_extension not in detection_type_list:\n",
    "            continue\n",
    "            \n",
    "        if file_extension in img_extension_list:\n",
    "            shutil.copy(os.path.join(images_path, filename), os.path.join(pre_process_path, f\"{file_name}_page_0.png\"))\n",
    "        else:\n",
    "            \n",
    "            with pdfplumber.open(os.path.join(images_path, filename)) as pdf:\n",
    "                for page_num, page in enumerate(pdf.pages):\n",
    "                    img = page.to_image()\n",
    "                    pdf_image = page.to_image().original\n",
    "    \n",
    "                    # å°†åŸå§‹å›¾åƒæ•°æ®è½¬æ¢ä¸º OpenCV å›¾åƒå¯¹è±¡\n",
    "                    open_cv_image = cv2.cvtColor(np.array(pdf_image), cv2.COLOR_RGB2BGR)\n",
    "                    cv2.imwrite(os.path.join(pre_process_path, f\"{file_name}_page_{page_num}.png\"), open_cv_image)\n",
    "                \n",
    "    return res_dict\n",
    "\n",
    "\n",
    "def predict_image_class(task_id, images_path, pre_process_path, model, res_dict):\n",
    "    # åŠ è½½å›¾åƒå¹¶è¿›è¡Œé¢„å¤„ç†\n",
    "    pre_process_files = os.listdir(pre_process_path)\n",
    "    pre_process_files_count = len(pre_process_files)\n",
    "    result_path = os.path.join(\"output\", \"detect\", task_id)\n",
    "        \n",
    "        \n",
    "    colors = np.random.randint(125, 255, (80, 3))\n",
    "    \n",
    "    for idx, img_name in enumerate(pre_process_files):\n",
    "        print(f\"Task_id:{task_id} {idx}/{pre_process_files_count} img_name: {img_name}\")\n",
    "\n",
    "        file_extension = img_name.split(\".\")[-1]\n",
    "        \n",
    "        if file_extension != \"png\":\n",
    "            continue\n",
    "            \n",
    "        file_name = img_name.split(\"_page\")[0]\n",
    "        \n",
    "        matching_keys = [key for key in res_dict.keys() if file_name in key]\n",
    "        if not matching_keys:\n",
    "            continue\n",
    "            \n",
    "        related_pdf_name = matching_keys[0]\n",
    "\n",
    "        img = cv2.imread(os.path.join(pre_process_path, img_name))\n",
    "        \n",
    "        # è¿›è¡Œç›®æ ‡æ£€æµ‹\n",
    "        results = model(img)\n",
    "        \n",
    "        # æ˜¾ç¤ºæ£€æµ‹ç»“æœ\n",
    "        # results.show()\n",
    "        color = colors[int(random.randint(1, 10))]\n",
    "#         print(\"color\", color)\n",
    "        \n",
    "        # æˆ–è€…è·å–æ£€æµ‹åˆ°çš„å¯¹è±¡ä¿¡æ¯å¹¶è¿›è¡Œåç»­å¤„ç†\n",
    "        detected_objects = results.pandas().xyxy[0]\n",
    "#         print(detected_objects)\n",
    "        \n",
    "        for index, obj in detected_objects.iterrows():\n",
    "            x1, y1, x2, y2, conf, label = int(obj[0]), int(obj[1]), int(obj[2]), int(obj[3]), obj[4], int(obj[5])\n",
    "#             print(f\"x1:{x1} x2:{x2} y1:{y1} y2:{y2} conf:{conf} Label: {label}\")\n",
    "        #     ç”»å‡ºè¾¹ç•Œæ¡†\n",
    "    \n",
    "            if conf < 0.5:\n",
    "                continue\n",
    "                \n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (int(color[0]), int(color[1]), int(color[2])), 2)\n",
    "        \n",
    "        #     # æ ‡ç­¾æ–‡æœ¬\n",
    "            label_text = f\"{model.names[label]}: {conf:.2f}\"\n",
    "        \n",
    "        #     # åœ¨è¾¹ç•Œæ¡†ä¸Šæ–¹æ˜¾ç¤ºç±»åˆ«æ ‡ç­¾å’Œç½®ä¿¡åº¦\n",
    "            cv2.putText(img, label_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (int(color[0]), int(color[1]), int(color[2])), 2)\n",
    "            \n",
    "            \n",
    "        \n",
    "            detection_res = {\n",
    "                \"class_id\": int(label),\n",
    "                \"label\": label_text,\n",
    "                \"bbox\": [x1, y1, x2, y2],\n",
    "                \"score\": conf,\n",
    "            }\n",
    "\n",
    "            if not res_dict[related_pdf_name].get(\"result\"):\n",
    "                res_dict[related_pdf_name][\"result\"] = list()\n",
    "    \n",
    "            res_dict[related_pdf_name][\"result\"].append(detection_res)\n",
    "            \n",
    "#             cv2.imwrite(os.path.join(result_path, 'output.jpg'), img)\n",
    "        \n",
    "            print(f'Task: {task_id} The file {img_name} predicted current object class is: {label_text} axis: {x1} {y1} {x2} {y2}')\n",
    "            cv2.imwrite(os.path.join(result_path, f'{file_name}.jpg'), img)\n",
    "\n",
    "        print(f'Task: {task_id} The file {img_name} predicted done.')\n",
    "\n",
    "        \n",
    "    return res_dict\n",
    "\n",
    "        \n",
    "def handler(detect_floder, task_id, node):\n",
    "    # è®¾ç½®ç¼“å­˜ç›®å½•\n",
    "    cache_dir = 'YOLO'\n",
    "    torch.hub.set_dir(cache_dir)\n",
    "\n",
    "    \n",
    "\n",
    "    # å®šä¹‰æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„\n",
    "    model_weights_path = 'YOLO/ultralytics_yolov5_master/yolov5s.pt'\n",
    "    \n",
    "    \n",
    "    # åŠ è½½æ¨¡å‹\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # model = attempt_load(model_weights_path)\n",
    "    \n",
    "    \n",
    "    # Model\n",
    "    # ../: æºç›®å½•, æŸ¥æ‰¾ hubconf.py, æ¨¡å‹æ–‡ä»¶ç­‰ï¼Œ'yolov5s'ï¼šæ‰¾æ¨¡å‹æ–‡ä»¶ï¼Œæ²¡æœ‰ä¼šä¸‹è½½  ; source='local' æœ¬åœ°åŠ è½½æ¨¡å‹\n",
    "    model = torch.hub.load('YOLO/ultralytics_yolov5_master', 'yolov5s', source='local')  # or yolov5m, yolov5l, yolov5x, custom\n",
    "\n",
    "\n",
    "    model.eval()  # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼\n",
    "\n",
    "\n",
    "    model = model.to(device)\n",
    "    print(\"model loaded\")\n",
    "    \n",
    "    images_path = os.path.join(\"temp_storage\", detect_floder)\n",
    "\n",
    "    pre_process_path = os.path.join(images_path, \"pre_process\")\n",
    "    if not os.path.exists(pre_process_path):\n",
    "        os.mkdir(pre_process_path)\n",
    "\n",
    "    # é¢„æµ‹å›¾åƒç±»åˆ«\n",
    "\n",
    "    res_dict = pre_process(images_path, pre_process_path)\n",
    "    res = predict_image_class(task_id, images_path, pre_process_path, model, res_dict)\n",
    "    print(res)\n",
    "    \n",
    "    \n",
    "    # Todo: é‡Šæ”¾èµ„æºï¼Œ ç»“æœå¢åŠ åˆ° MongoDB\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    detect_floder = \"detect_demo1\"\n",
    "    task_id = \"123\"\n",
    "    node = \"worker1\"\n",
    "    handler(detect_floder, task_id, node)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a55118-509b-40df-8dfa-df5e5d9b5d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
