{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92286a6c-9a71-4445-8201-0c92ebf3316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bc31b6b-8e0b-4f75-8f9c-6edfd564809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Display image for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "def visualize_model_predictions(model,img_path):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "\n",
    "    img = Image.open(img_path)\n",
    "    img = data_transforms['val'](img)\n",
    "    img = img.unsqueeze(0)\n",
    "    img = img.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        ax = plt.subplot(2,2,1)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'Predicted: {class_names[preds[0]]}')\n",
    "        imshow(img.cpu().data[0])\n",
    "        \n",
    "        model.train(mode=was_training)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bafef2d9-4809-484b-9140-d14b02f9030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def train_model(task_id, model, criterion, optimizer, scheduler, batch_size, num_epochs=25, dataset_name=None):\n",
    "    since = time.time()\n",
    "    \n",
    "    \n",
    "    result_path = os.path.join(\"output\", \"train\", task_id)\n",
    "    if not os.path.exists(result_path): \n",
    "        os.makedirs(result_path)\n",
    "    \n",
    "    pretrained_model_path = os.path.join('models', task_id)\n",
    "    if not os.path.exists(pretrained_model_path): \n",
    "        os.makedirs(pretrained_model_path)\n",
    "        \n",
    "    \n",
    "    if not dataset_name:\n",
    "        dataset_name = \"mini\"\n",
    "    \n",
    "    dataset_path = os.path.join('dataset', dataset_name)\n",
    "    \n",
    "    \n",
    "    image_datasets = {x: datasets.ImageFolder(os.path.join(dataset_path, x),\n",
    "                                              data_transforms[x]) for x in ['train', 'val']}\n",
    "\n",
    "    class_names = image_datasets['train'].classes\n",
    "\n",
    "    \n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "    \n",
    "    \n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    best_model_params_path = os.path.join(pretrained_model_path, 'best_model_params.pt')\n",
    "    torch.save(model.state_dict(), best_model_params_path)\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Todo: 加 redis \n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                # Todo: 加 redis 日志\n",
    "                \n",
    "                if (i+1) % 10 == 0:  # Print every 10th iteration\n",
    "                    print(f'Epoch: {epoch} Phase: {phase} Iter: {i+1}/{len(dataloaders[phase])} '\n",
    "                          f'Loss: {running_loss / dataset_sizes[phase]:.4f} Acc: {running_corrects.double() / dataset_sizes[phase]:.4f}')\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                res_model_path = os.path.join(pretrained_model_path, f'resnet_epoch_{epoch}.pt')\n",
    "                torch.save(model.state_dict(), res_model_path)\n",
    "#                 torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(torch.load(best_model_params_path))\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71082a18-ee2a-4966-b83c-1db83a081094",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name is not provided, use default model\n",
      "model loaded\n",
      "Epoch 0/1\n",
      "----------\n",
      "Epoch: 0 Phase: train Iter: 10/122 Loss: 0.0584 Acc: 0.0410\n",
      "Epoch: 0 Phase: train Iter: 20/122 Loss: 0.1072 Acc: 0.0984\n",
      "Epoch: 0 Phase: train Iter: 30/122 Loss: 0.1475 Acc: 0.1639\n",
      "Epoch: 0 Phase: train Iter: 40/122 Loss: 0.1911 Acc: 0.2254\n",
      "Epoch: 0 Phase: train Iter: 50/122 Loss: 0.2298 Acc: 0.2869\n",
      "Epoch: 0 Phase: train Iter: 60/122 Loss: 0.2877 Acc: 0.3361\n",
      "Epoch: 0 Phase: train Iter: 70/122 Loss: 0.3302 Acc: 0.4016\n",
      "Epoch: 0 Phase: train Iter: 80/122 Loss: 0.3881 Acc: 0.4549\n",
      "Epoch: 0 Phase: train Iter: 90/122 Loss: 0.4462 Acc: 0.5041\n",
      "Epoch: 0 Phase: train Iter: 100/122 Loss: 0.4908 Acc: 0.5574\n",
      "Epoch: 0 Phase: train Iter: 110/122 Loss: 0.5401 Acc: 0.6107\n",
      "Epoch: 0 Phase: train Iter: 120/122 Loss: 0.6034 Acc: 0.6598\n",
      "train Loss: 0.6161 Acc: 0.6639\n",
      "Epoch: 0 Phase: val Iter: 10/77 Loss: 0.0384 Acc: 0.1242\n",
      "Epoch: 0 Phase: val Iter: 20/77 Loss: 0.1040 Acc: 0.2353\n",
      "Epoch: 0 Phase: val Iter: 30/77 Loss: 0.1778 Acc: 0.3333\n",
      "Epoch: 0 Phase: val Iter: 40/77 Loss: 0.2323 Acc: 0.4379\n",
      "Epoch: 0 Phase: val Iter: 50/77 Loss: 0.2641 Acc: 0.5556\n",
      "Epoch: 0 Phase: val Iter: 60/77 Loss: 0.3444 Acc: 0.6601\n",
      "Epoch: 0 Phase: val Iter: 70/77 Loss: 0.3925 Acc: 0.7712\n",
      "val Loss: 0.4415 Acc: 0.8497\n",
      "Epoch 1/1\n",
      "----------\n",
      "Epoch: 1 Phase: train Iter: 10/122 Loss: 0.0284 Acc: 0.0738\n",
      "Epoch: 1 Phase: train Iter: 20/122 Loss: 0.1007 Acc: 0.1148\n",
      "Epoch: 1 Phase: train Iter: 30/122 Loss: 0.1398 Acc: 0.1803\n",
      "Epoch: 1 Phase: train Iter: 40/122 Loss: 0.2283 Acc: 0.2172\n",
      "Epoch: 1 Phase: train Iter: 50/122 Loss: 0.2868 Acc: 0.2664\n",
      "Epoch: 1 Phase: train Iter: 60/122 Loss: 0.3326 Acc: 0.3279\n",
      "Epoch: 1 Phase: train Iter: 70/122 Loss: 0.3848 Acc: 0.3811\n",
      "Epoch: 1 Phase: train Iter: 80/122 Loss: 0.4355 Acc: 0.4426\n",
      "Epoch: 1 Phase: train Iter: 90/122 Loss: 0.5137 Acc: 0.4836\n",
      "Epoch: 1 Phase: train Iter: 100/122 Loss: 0.5626 Acc: 0.5451\n",
      "Epoch: 1 Phase: train Iter: 110/122 Loss: 0.6022 Acc: 0.6107\n",
      "Epoch: 1 Phase: train Iter: 120/122 Loss: 0.6612 Acc: 0.6557\n",
      "train Loss: 0.6685 Acc: 0.6680\n",
      "Epoch: 1 Phase: val Iter: 10/77 Loss: 0.0383 Acc: 0.1111\n",
      "Epoch: 1 Phase: val Iter: 20/77 Loss: 0.0879 Acc: 0.2157\n",
      "Epoch: 1 Phase: val Iter: 30/77 Loss: 0.1351 Acc: 0.3203\n",
      "Epoch: 1 Phase: val Iter: 40/77 Loss: 0.2109 Acc: 0.4118\n",
      "Epoch: 1 Phase: val Iter: 50/77 Loss: 0.2613 Acc: 0.5229\n",
      "Epoch: 1 Phase: val Iter: 60/77 Loss: 0.3041 Acc: 0.6275\n",
      "Epoch: 1 Phase: val Iter: 70/77 Loss: 0.3579 Acc: 0.7386\n",
      "val Loss: 0.4028 Acc: 0.8039\n",
      "Training complete in 0m 17s\n",
      "Best val Acc: 0.849673\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "def start(task_id, epoch, batch_size, learning_rate, dataset_name, node, optimizer=\"Adam\", model_name=None):\n",
    "    # data_dir = 'dataset'\n",
    "\n",
    "    \n",
    "    if not model_name:\n",
    "        print(f\"Model name is not provided, use default model\")\n",
    "        model_path = \"pretrain_models/resnet_epoch_3.pt\"\n",
    "    else:\n",
    "        model_path = os.path.join(\"models\", model_name)\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"{model_name} does not exist, use default model\")\n",
    "            model_path = \"pretrain_models/resnet_epoch_3.pt\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 定义本地预训练模型的路径\n",
    "    model_path = 'models/resnet50.pth'\n",
    "    \n",
    "    # 实例化一个 ResNet-50 模型\n",
    "    model_ft = models.resnet50()\n",
    "    \n",
    "    # 加载本地预训练模型的权重\n",
    "    checkpoint = torch.load(model_path)\n",
    "    model_ft.load_state_dict(checkpoint)\n",
    "    \n",
    "    \n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    # Here the size of each output sample is set to 2.\n",
    "    # Alternatively, it can be generalized to ``nn.Linear(num_ftrs, len(class_names))``.\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    \n",
    "    \n",
    "    model_ft = model_ft.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Observe that all parameters are being optimized\n",
    "    if optimizer == \"Adam\":\n",
    "        optimizer_ft = optim.Adam(model_ft.parameters(), lr=learning_rate) \n",
    "    else:\n",
    "        optimizer_ft = optim.SGD(model_ft.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    \n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "    \n",
    "    # Todo: 增加日志\n",
    "    print(\"model loaded\")\n",
    "    \n",
    "    model = train_model(task_id, model_ft, criterion, optimizer_ft, exp_lr_scheduler, batch_size=batch_size, num_epochs=epoch, dataset_name=dataset_name)\n",
    "    \n",
    "    # 设置状态，更新 redis 和 MongoDB 状态，释放资源\n",
    "    # Todo: 释放资源\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    task_id = \"123\"\n",
    "    epoch = 2\n",
    "    batch_size = 2\n",
    "    learning_rate = 0.0001\n",
    "    dataset_name = \"mini\"\n",
    "    node = \"worker1\"\n",
    "    optimizer = \"Adam\"\n",
    "\n",
    "    start(task_id, epoch, batch_size, learning_rate, dataset_name, node)\n",
    "    # start(batch_size, epoch, lr, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147448e8-a33b-4690-a95e-ced7b17e6788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
