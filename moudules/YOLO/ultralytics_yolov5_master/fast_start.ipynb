{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c5464eb-7055-4946-8617-7d3dd91d10dd",
   "metadata": {},
   "source": [
    "# ä½¿ç”¨æœ¬åœ°æ¨¡å‹ âœ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb0a065b-26f7-40b9-b8b4-221cf02b0ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ğŸš€ 2023-11-21 Python-3.8.12 torch-1.11.0+cu113 CUDA:0 (Tesla K80, 11441MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 224 layers, 7266973 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color [243 156 209]\n",
      "         xmin        ymin        xmax        ymax  confidence  class  \\\n",
      "0   53.802078  396.445923  227.794983  883.951111    0.883670      0   \n",
      "1  673.578308  398.884033  810.000000  876.403625    0.872997      0   \n",
      "2  219.302109  409.058685  345.095520  862.395508    0.835829      0   \n",
      "3    9.409970  209.878723  798.141785  740.623779    0.763868      5   \n",
      "4    0.338889  550.339478   74.638893  883.972534    0.699320      0   \n",
      "5  666.431824  823.705811  808.421631  881.111145    0.458064     36   \n",
      "6  656.903992  625.371521  689.216858  716.204895    0.269094     10   \n",
      "\n",
      "           name  \n",
      "0        person  \n",
      "1        person  \n",
      "2        person  \n",
      "3           bus  \n",
      "4        person  \n",
      "5    skateboard  \n",
      "6  fire hydrant  \n",
      "x1:53 x2:227 y1:396 y2:883 conf:0.8836702704429626 Label: 0\n",
      "x1:673 x2:810 y1:398 y2:876 conf:0.8729968667030334 Label: 0\n",
      "x1:219 x2:345 y1:409 y2:862 conf:0.8358286619186401 Label: 0\n",
      "x1:9 x2:798 y1:209 y2:740 conf:0.7638677358627319 Label: 5\n",
      "x1:0 x2:74 y1:550 y2:883 conf:0.699320375919342 Label: 0\n",
      "x1:666 x2:808 y1:823 y2:881 conf:0.4580642879009247 Label: 36\n",
      "x1:656 x2:689 y1:625 y2:716 conf:0.26909399032592773 Label: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# è®¾ç½®ç¼“å­˜ç›®å½•\n",
    "# cache_dir = '/mnt/Demo/YOLO/'\n",
    "cache_dir = '.'\n",
    "torch.hub.set_dir(cache_dir)\n",
    "\n",
    "colors = np.random.randint(125, 255, (80, 3))\n",
    "\n",
    "# å®šä¹‰æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„\n",
    "model_weights_path = 'yolov5s.pt'\n",
    "\n",
    "# åŠ è½½æ¨¡å‹\n",
    "# model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_weights_path)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    " \n",
    "# Model\n",
    "model = torch.hub.load('./', 'yolov5s', source='local')  # or yolov5m, yolov5l, yolov5x, custom\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "# åŠ è½½å›¾åƒï¼ˆæˆ–è§†é¢‘å¸§ï¼‰è¿›è¡Œç›®æ ‡æ£€æµ‹\n",
    "image_path = 'bus.jpg'\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# è¿›è¡Œç›®æ ‡æ£€æµ‹\n",
    "results = model(img)\n",
    "\n",
    "# æ˜¾ç¤ºæ£€æµ‹ç»“æœ\n",
    "# results.show()\n",
    "color = colors[int(random.randint(1, 10))]\n",
    "print(\"color\", color)\n",
    "\n",
    "# æˆ–è€…è·å–æ£€æµ‹åˆ°çš„å¯¹è±¡ä¿¡æ¯å¹¶è¿›è¡Œåç»­å¤„ç†\n",
    "detected_objects = results.pandas().xyxy[0]\n",
    "print(detected_objects)\n",
    "\n",
    "for index, obj in detected_objects.iterrows():\n",
    "    x1, y1, x2, y2, conf, label = int(obj[0]), int(obj[1]), int(obj[2]), int(obj[3]), obj[4], int(obj[5])\n",
    "    print(f\"x1:{x1} x2:{x2} y1:{y1} y2:{y2} conf:{conf} Label: {label}\")\n",
    "#     ç”»å‡ºè¾¹ç•Œæ¡†\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (int(color[0]), int(color[1]), int(color[2])), 2)\n",
    "\n",
    "#     # æ ‡ç­¾æ–‡æœ¬\n",
    "    label_text = f\"{model.names[label]}: {conf:.2f}\"\n",
    "\n",
    "#     # åœ¨è¾¹ç•Œæ¡†ä¸Šæ–¹æ˜¾ç¤ºç±»åˆ«æ ‡ç­¾å’Œç½®ä¿¡åº¦\n",
    "    cv2.putText(img, label_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (int(color[0]), int(color[1]), int(color[2])), 2)\n",
    "    \n",
    "cv2.imwrite('output.jpg', img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c511b55a-3285-48f0-bc27-02975eae8823",
   "metadata": {},
   "source": [
    "# ä½¿ç”¨ç½‘ç»œæ¨¡å‹ âœ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea697be-10a7-4725-b38c-44c968baa9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# è®¾ç½®ç¼“å­˜ç›®å½•\n",
    "cache_dir = '/mnt/Demo/YOLO/'\n",
    "torch.hub.set_dir(cache_dir)\n",
    "\n",
    "colors = np.random.randint(125, 255, (80, 3))\n",
    "\n",
    "# å®šä¹‰æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„\n",
    "model_weights_path = 'yolov5s.pt'\n",
    "\n",
    "# åŠ è½½æ¨¡å‹\n",
    "# model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_weights_path)\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', path=model_weights_path)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "# åŠ è½½å›¾åƒï¼ˆæˆ–è§†é¢‘å¸§ï¼‰è¿›è¡Œç›®æ ‡æ£€æµ‹\n",
    "image_path = 'bus.jpg'\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# è¿›è¡Œç›®æ ‡æ£€æµ‹\n",
    "results = model(img)\n",
    "\n",
    "# æ˜¾ç¤ºæ£€æµ‹ç»“æœ\n",
    "# results.show()\n",
    "color = colors[int(random.randint(1, 10))]\n",
    "print(\"color\", color)\n",
    "\n",
    "# æˆ–è€…è·å–æ£€æµ‹åˆ°çš„å¯¹è±¡ä¿¡æ¯å¹¶è¿›è¡Œåç»­å¤„ç†\n",
    "detected_objects = results.pandas().xyxy[0]\n",
    "print(detected_objects)\n",
    "\n",
    "for index, obj in detected_objects.iterrows():\n",
    "    x1, y1, x2, y2, conf, label = int(obj[0]), int(obj[1]), int(obj[2]), int(obj[3]), obj[4], int(obj[5])\n",
    "    print(f\"x1:{x1} x2:{x2} y1:{y1} y2:{y2} conf:{conf} Label: {label}\")\n",
    "#     ç”»å‡ºè¾¹ç•Œæ¡†\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (int(color[0]), int(color[1]), int(color[2])), 2)\n",
    "\n",
    "#     # æ ‡ç­¾æ–‡æœ¬\n",
    "    label_text = f\"{model.names[label]}: {conf:.2f}\"\n",
    "\n",
    "#     # åœ¨è¾¹ç•Œæ¡†ä¸Šæ–¹æ˜¾ç¤ºç±»åˆ«æ ‡ç­¾å’Œç½®ä¿¡åº¦\n",
    "    cv2.putText(img, label_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (int(color[0]), int(color[1]), int(color[2])), 2)\n",
    "    \n",
    "cv2.imwrite('output.jpg', img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc3be6a-d5c8-4a29-b9a4-e2b52f01a6c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
